{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e8c422-cc19-4d89-8f96-003c36cf7c33",
   "metadata": {},
   "source": [
    "## Lab 7: Eel Distribution Modeling with XGBoost\n",
    "\n",
    "**Reference Paper:** [Elith et al. (2008)](https://ucsb.box.com/s/6k7636wsbogdg3orarxrlowke0ounbic)\n",
    "\n",
    "In this lab, you will model the distribution of the eel species *Anguilla australis* using **boosted classification trees (BCTs)**, a machine learning technique that improves predictive performance by combining multiple decision trees. Elith et al. (2008) offered an early implementation of BRTs in an ecological setting to understand how environmental variables influence eel distribution.\n",
    "\n",
    "You will work with **two datasets**:\n",
    "1. **Training Data** – Used to build and evaluate your XGBoost model.\n",
    "2. **Evaluation Data** – Used to assess model performance on unseen data.\n",
    "\n",
    "To achieve the following objectives:\n",
    "- Train and fine-tune an **XGBoost** model for classification of species presence/absence data.\n",
    "- Compare your model’s performance to the approach used by Elith et al.\n",
    "\n",
    "\n",
    "**Wherever applicable in this lab, use a random state of 808.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39e743-8686-4f51-85ee-7c1925002f5f",
   "metadata": {},
   "source": [
    "### Step 0: Load libraries and data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd687480-182a-4416-9cdd-10eb33d147d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angaus          int64\n",
      "SegSumT       float64\n",
      "SegTSeas      float64\n",
      "SegLowFlow    float64\n",
      "DSDist        float64\n",
      "DSMaxSlope    float64\n",
      "USAvgT        float64\n",
      "USRainDays    float64\n",
      "USSlope       float64\n",
      "USNative      float64\n",
      "DSDam           int64\n",
      "Method         object\n",
      "LocSed        float64\n",
      "dtype: object\n",
      "Angaus_obs      int64\n",
      "SegSumT       float64\n",
      "SegTSeas      float64\n",
      "SegLowFlow    float64\n",
      "DSDist        float64\n",
      "DSMaxSlope    float64\n",
      "USAvgT        float64\n",
      "USRainDays    float64\n",
      "USSlope       float64\n",
      "USNative      float64\n",
      "DSDam           int64\n",
      "Method         object\n",
      "LocSed        float64\n",
      "dtype: object\n",
      "['electric' 'spo' 'trap' 'mixture' 'net']\n",
      "['electric' 'net' 'mixture' 'spo' 'trap']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import uniform, randint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Download the datasets\n",
    "model_data = pd.read_csv(\"data/model.data.csv\").drop(columns=['Site'])\n",
    "eval_data = pd.read_csv(\"data/eval.data.csv\")\n",
    "\n",
    "# View model data dtypes\n",
    "print(model_data.dtypes)\n",
    "print(eval_data.dtypes)\n",
    "\n",
    "# View uniques in method column\n",
    "print(model_data['Method'].unique())\n",
    "print(eval_data['Method'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20f3a549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Angaus_obs</th>\n",
       "      <th>SegSumT</th>\n",
       "      <th>SegTSeas</th>\n",
       "      <th>SegLowFlow</th>\n",
       "      <th>DSDist</th>\n",
       "      <th>DSMaxSlope</th>\n",
       "      <th>USAvgT</th>\n",
       "      <th>USRainDays</th>\n",
       "      <th>USSlope</th>\n",
       "      <th>USNative</th>\n",
       "      <th>DSDam</th>\n",
       "      <th>Method</th>\n",
       "      <th>LocSed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.017</td>\n",
       "      <td>5.230</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>1.980</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>electric</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16.8</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>1.002</td>\n",
       "      <td>2.240</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>electric</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.023</td>\n",
       "      <td>162.280</td>\n",
       "      <td>5.14</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.806</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>electric</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.003</td>\n",
       "      <td>4.050</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.14</td>\n",
       "      <td>3.300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>net</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.023</td>\n",
       "      <td>127.030</td>\n",
       "      <td>1.72</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>1.940</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>electric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.024</td>\n",
       "      <td>171.550</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.277</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>electric</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.513</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>trap</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>1.063</td>\n",
       "      <td>171.620</td>\n",
       "      <td>1.72</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>0.210</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "      <td>electric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>1.055</td>\n",
       "      <td>67.980</td>\n",
       "      <td>1.72</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>1.220</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "      <td>electric</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.006</td>\n",
       "      <td>79.740</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.514</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>electric</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Angaus_obs  SegSumT  SegTSeas  SegLowFlow   DSDist  DSMaxSlope  USAvgT  \\\n",
       "0             0     16.6      1.01       1.017    5.230        0.29   -1.40   \n",
       "1             1     16.8     -0.51       1.002    2.240        0.00    0.27   \n",
       "2             0     16.3      0.76       1.023  162.280        5.14   -0.60   \n",
       "3             0     15.6      1.56       1.003    4.050        0.57    1.14   \n",
       "4             0     14.6     -0.20       1.023  127.030        1.72   -1.90   \n",
       "..          ...      ...       ...         ...      ...         ...     ...   \n",
       "495           0     18.2      0.39       1.024  171.550        0.57   -0.20   \n",
       "496           0     18.6      1.43       1.001    0.807        0.57    0.25   \n",
       "497           0     16.8     -3.71       1.063  171.620        1.72   -6.00   \n",
       "498           0     16.6     -0.69       1.055   67.980        1.72   -0.90   \n",
       "499           0     16.9      0.77       1.006   79.740        1.72    0.39   \n",
       "\n",
       "     USRainDays  USSlope  USNative  DSDam    Method  LocSed  \n",
       "0         1.980     10.0      1.00      0  electric     4.9  \n",
       "1         0.460      0.7      0.00      0  electric     2.3  \n",
       "2         0.806     21.4      0.66      0  electric     4.3  \n",
       "3         3.300      0.9      0.75      0       net     1.0  \n",
       "4         1.940     28.9      0.97      0  electric     NaN  \n",
       "..          ...      ...       ...    ...       ...     ...  \n",
       "495       1.277      9.6      0.10      0  electric     3.6  \n",
       "496       1.513     10.0      0.00      0      trap     NaN  \n",
       "497       0.210     10.1      0.83      1  electric     NaN  \n",
       "498       1.220     15.1      0.47      0  electric     4.8  \n",
       "499       1.514     16.9      0.10      0  electric     5.0  \n",
       "\n",
       "[500 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e16c25",
   "metadata": {},
   "source": [
    "### Step 1:Initial Data Preprocessing\n",
    "Let's get started by preparing our data. `Angaus` will be our target variable(`y`), and all other variables will be our features (`X`). Then encode the categorical feature using `LabelEncoder()`. The final step will be a bit different this time.  We don't need to split off testing data for the final model evaluation; a separate set (`eval_data`) will be used as in Elith et al.  We do, however, need to split our data in order to do the early stopping process. When splitting your data into training and validation, use a test size of 0.2 and a random state of 808. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92f8a3c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 4 1 2]\n",
      "[0 2 1 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Encode Method column to numeric in model data\n",
    "label_encoder = LabelEncoder()\n",
    "model_data['Method'] = label_encoder.fit_transform(model_data['Method'])\n",
    "\n",
    "# Encode Method column to numeric in eval data \n",
    "eval_data['Method'] = label_encoder.fit_transform(eval_data['Method'])\n",
    "\n",
    "# Should be 5 outputs just like original\n",
    "print(model_data['Method'].unique())\n",
    "print(eval_data['Method'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c9780da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Angaus_obs</th>\n",
       "      <th>SegSumT</th>\n",
       "      <th>SegTSeas</th>\n",
       "      <th>SegLowFlow</th>\n",
       "      <th>DSDist</th>\n",
       "      <th>DSMaxSlope</th>\n",
       "      <th>USAvgT</th>\n",
       "      <th>USRainDays</th>\n",
       "      <th>USSlope</th>\n",
       "      <th>USNative</th>\n",
       "      <th>DSDam</th>\n",
       "      <th>Method</th>\n",
       "      <th>LocSed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.017</td>\n",
       "      <td>5.230</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>1.980</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16.8</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>1.002</td>\n",
       "      <td>2.240</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.023</td>\n",
       "      <td>162.280</td>\n",
       "      <td>5.14</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.806</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.003</td>\n",
       "      <td>4.050</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.14</td>\n",
       "      <td>3.300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.023</td>\n",
       "      <td>127.030</td>\n",
       "      <td>1.72</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>1.940</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.024</td>\n",
       "      <td>171.550</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.277</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.513</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>1.063</td>\n",
       "      <td>171.620</td>\n",
       "      <td>1.72</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>0.210</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>1.055</td>\n",
       "      <td>67.980</td>\n",
       "      <td>1.72</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>1.220</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.006</td>\n",
       "      <td>79.740</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.514</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Angaus_obs  SegSumT  SegTSeas  SegLowFlow   DSDist  DSMaxSlope  USAvgT  \\\n",
       "0             0     16.6      1.01       1.017    5.230        0.29   -1.40   \n",
       "1             1     16.8     -0.51       1.002    2.240        0.00    0.27   \n",
       "2             0     16.3      0.76       1.023  162.280        5.14   -0.60   \n",
       "3             0     15.6      1.56       1.003    4.050        0.57    1.14   \n",
       "4             0     14.6     -0.20       1.023  127.030        1.72   -1.90   \n",
       "..          ...      ...       ...         ...      ...         ...     ...   \n",
       "495           0     18.2      0.39       1.024  171.550        0.57   -0.20   \n",
       "496           0     18.6      1.43       1.001    0.807        0.57    0.25   \n",
       "497           0     16.8     -3.71       1.063  171.620        1.72   -6.00   \n",
       "498           0     16.6     -0.69       1.055   67.980        1.72   -0.90   \n",
       "499           0     16.9      0.77       1.006   79.740        1.72    0.39   \n",
       "\n",
       "     USRainDays  USSlope  USNative  DSDam  Method  LocSed  \n",
       "0         1.980     10.0      1.00      0       0     4.9  \n",
       "1         0.460      0.7      0.00      0       0     2.3  \n",
       "2         0.806     21.4      0.66      0       0     4.3  \n",
       "3         3.300      0.9      0.75      0       2     1.0  \n",
       "4         1.940     28.9      0.97      0       0     NaN  \n",
       "..          ...      ...       ...    ...     ...     ...  \n",
       "495       1.277      9.6      0.10      0       0     3.6  \n",
       "496       1.513     10.0      0.00      0       4     NaN  \n",
       "497       0.210     10.1      0.83      1       0     NaN  \n",
       "498       1.220     15.1      0.47      0       0     4.8  \n",
       "499       1.514     16.9      0.10      0       0     5.0  \n",
       "\n",
       "[500 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dc69ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target and features\n",
    "X = model_data.drop(columns=['Angaus'])\n",
    "y = model_data['Angaus']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=808)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025a34e",
   "metadata": {},
   "source": [
    "### Step 2: Determine best number of trees using early stopping\n",
    "As a guard against overfitting while maximizing performance, we use **early stopping**. We start with a large number of trees and allow XGBoost to determine the optimal number by stopping training when the validation error no longer improves.\n",
    "\n",
    "The choice of hyperparameter starting values is important in this process. We begin with:\n",
    "- `n_estimators=1000` to ensure the model has enough capacity to learn meaningful patterns.\n",
    "- `learning_rate=0.1` as a reasonable default that balances learning speed and performance.\n",
    "- `eval_metric=\"logloss\"` as the metric of performance to optimize.\n",
    "- `early_stopping_rounds=50` to halt training if no improvement is seen for 50 rounds, preventing unnecessary computations.\n",
    "- `random_state = 808`\n",
    "\n",
    "We then `fit()` our specified baseline model, passing in the training sets as usual and specifying validation sets values for the `eval_set` parameter.\n",
    "\n",
    "Finally, get and print the best number of trees from the fitted baseline model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55bf0fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best number of trees is: 29\n"
     ]
    }
   ],
   "source": [
    "# Train a XGBoost model\n",
    "model = XGBClassifier(\n",
    "    n_estimators = 1000,\n",
    "    learning_rate = 0.1,\n",
    "    eval_metric = 'logloss',\n",
    "    early_stopping_rounds = 50,\n",
    "    random_state = 808)\n",
    "\n",
    "# Fit the model and specify validation sets\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose = 0)\n",
    "\n",
    "# Best number of trees from baseline model\n",
    "best_ntree = model.best_iteration\n",
    "print(f\"The best number of trees is: {best_ntree}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac1456",
   "metadata": {},
   "source": [
    "### Step 3: Tune Learning Rate\n",
    "\n",
    "The (`learning_rate` hyperparameter controls how much each tree contributes to improving the model's performance. A *higher* learning rate allows the model to learn quickly but risks missing the optimal solution and overfitting, while a *lower* learning rate makes learning slower but can improve generalization.\n",
    "\n",
    "To find the optimal value, we'll use **randomized search cross-validation** (`RandomizedSearchCV`) to test different learning rates in the 0.01 to 0.3 range. Instead of testing every possible value, this method samples a set number of candidates (`n_iter`) from a defined parameter distribution.  In this case, sampling 20 candidates from a uniform distribution between `0.01` and `0.31`. Check out the [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html) on `scipy.stats.uniform` to see how it differs from `random.uniform`. Be sure to use a random state of 808.\n",
    "\n",
    "After using `RandomizedSearchCV`, fit your model. Print the best learning rate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "393b5c0b-b212-440b-a052-0c9a7e406b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "The best learning rate is: 0.24294539164293216\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter distributions\n",
    "param_distributions = {\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "}\n",
    "\n",
    "# Set up RandmoizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_distributions, \n",
    "    n_iter = 20, \n",
    "    cv = 5, \n",
    "    verbose=1, \n",
    "    random_state = 808\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose = 0)\n",
    "\n",
    "# Print best learning rate\n",
    "best_rate = random_search.best_params_['learning_rate']\n",
    "print(f\"The best learning rate is: {best_rate}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71907b11",
   "metadata": {},
   "source": [
    "### Step 4: Tune Tree-Specific Parameters\n",
    "\n",
    "Now that we've determined the best number of tree and learning rate, we need to tune the complexity of individual trees in our model. Initialize your model with the best number of trees and learning rate.Then, define a parameter dictionary that takes on the following values:  \n",
    "\n",
    "- `max_depth`(Controls how deep each tree can grow.  Takes integer values): A random integer from 3 to 10 ( inclusive of 3 and 10)\n",
    "- `min_child_weight`( Determines the minimum number of samples required in a leaf node. Takes integer values) : A random integer from 1 to 10 ( inclusive of 1 and 10)\n",
    "- `gamma` (Defines the minimum loss reduction needed to make a further split in a tree. Can take on values from a continuous range):  A uniform distribution from 0.05 to 0.10 - once again remember to check the `scipy.stats.uniform()` documentation! \n",
    "- `random_state = 808`\n",
    "\n",
    "To find the best combination, we again use `RandomizedSearchCV`, allowing us to efficiently sample hyperparameters and evaluate different configurations using cross-validation. After fitting the model, print the best parameters. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95c411a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "The best parameters are: {'gamma': 0.09883676100048099, 'max_depth': 9, 'min_child_weight': 7}\n"
     ]
    }
   ],
   "source": [
    "# Train a new  model with the best hyperparameters\n",
    "model = XGBClassifier(\n",
    "    n_estimators = best_ntree,\n",
    "    learning_rate = best_rate,\n",
    "    eval_metric = 'logloss',\n",
    "    early_stopping_rounds = 50,\n",
    "    random_state = 808\n",
    ")\n",
    "\n",
    "# Define new parameter distribution\n",
    "param_dist = {\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'gamma': uniform(0.05, 0.05)\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_dist, \n",
    "    n_iter = 10, \n",
    "    cv = 5, \n",
    "    verbose=1, \n",
    "    random_state = 808\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose = 0)\n",
    "\n",
    "# Print best parameters\n",
    "best_tree_params = random_search.best_params_\n",
    "print(f\"The best parameters are: {best_tree_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168bf81",
   "metadata": {},
   "source": [
    "### Step 5: Tune Stochastic Components\n",
    "\n",
    "Now, we are finally ready to tune the stochastic components of the XGBoost model.  These parameters help prevent overfitting by reducing correlation between trees. Initialize your model with the best number of trees, best learning rate,and your optimized tree values (**Note**: you can use \\**best_tree_parameters to unpack the the dictionary of optimzed tree values) .Then, define a parameter dictionary that takes on the following values:  \n",
    "\n",
    "- `subsample` (Controls the fraction of training samples used for each boosting round) : A uniform distribution between .5 and .10 (remeber to check `scipy.stats.uniform()` documentation! )\n",
    "- `colsample_bytree`(Specifies the fraction of features to consider when building each tree) : A uniform distribution between .5 and .10\n",
    "- `random_state = 808`\n",
    "\n",
    "We again use `RandomizedSearchCV` to find the best combination of these parameters. After fitting the model, print the best parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32a61aee-57b1-470b-aa07-488dbe70f898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "The best parameters are: {'colsample_bytree': 0.7435738316840477, 'subsample': 0.8699203563223885}\n"
     ]
    }
   ],
   "source": [
    "# Define paramater distribution\n",
    "param_dist = {\n",
    "    'subsample': uniform(0.5, 0.5),\n",
    "    'colsample_bytree': uniform(0.5, 0.5)\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_dist, \n",
    "    n_iter = 10, \n",
    "    cv = 5, \n",
    "    verbose=1, \n",
    "    random_state = 808\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train, eval_set=[(X_test, y_test )], verbose = 0)\n",
    "\n",
    "# Print best parameters\n",
    "best_stochastic_params = random_search.best_params_\n",
    "print(f\"The best parameters are: {best_stochastic_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355cd2d2",
   "metadata": {},
   "source": [
    "### Step 6: Final Model Training and Evaluation\n",
    "\n",
    "With the best hyperparameters selected, we now train the final model on the full training dataset and evaluate it on the separate evaluation dataset.\n",
    "\n",
    "1. Prepare the evaluation data in the same manner as you did the training data\n",
    "\n",
    "2. Train final model using the best parameters found in previous tuning steps (`best_tree_params`, `best_stochastic_params`).Set  `eval_metric = \"logloss\"` \n",
    "\n",
    "3. Fit the model to the full training dataset and predict on the evaluation data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b68c8624-942b-4d1b-a665-77ca99685186",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define eval data\n",
    "X_eval = eval_data.drop(columns=['Angaus_obs'])\n",
    "y_eval = eval_data['Angaus_obs']\n",
    "\n",
    "# Train a new model with the best hyperparameters\n",
    "model = XGBClassifier(\n",
    "    n_estimators = best_ntree,\n",
    "    learning_rate = best_rate,\n",
    "    max_depth = best_tree_params['max_depth'],\n",
    "    min_child_weight = best_tree_params['min_child_weight'],\n",
    "    gamma = best_tree_params['gamma'],\n",
    "    subsample = best_stochastic_params['subsample'],\n",
    "    colsample_bytree = best_stochastic_params['colsample_bytree'],\n",
    "    eval_metric = 'logloss',\n",
    "    early_stopping_rounds = 50,\n",
    "    random_state = 808\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, eval_set=[(X_eval, y_eval)], verbose = 0)\n",
    "\n",
    "# Predict on eval data\n",
    "y_pred = model.predict_proba(X_eval)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f39d80a",
   "metadata": {},
   "source": [
    "### Step 7: Model Performance\n",
    "\n",
    "Compute and print the AUC and feature importances for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c6327c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.9533642274001836\n"
     ]
    }
   ],
   "source": [
    "# Compute training AUC\n",
    "train_preds = model.predict_proba(X)[:,1]\n",
    "train_auc = roc_auc_score(y, train_preds)\n",
    "print(f\"Training AUC: {train_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc9df468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Value: 0.874\n"
     ]
    }
   ],
   "source": [
    "# Compute evaluation AUC\n",
    "auc = roc_auc_score(y_eval, y_pred)\n",
    "print(f\"AUC Value: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afb28dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the feature importances\n",
    "importances = model.feature_importances_\n",
    "importances_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "importances_df = importances_df.sort_values('importance', ascending = False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importances_df, x='importance', y='feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476ef1d",
   "metadata": {},
   "source": [
    "### Step 8: The comparison\n",
    "How does your model's performance compare to the of Elith et al. (See Tables 2 and 3)?  Is there another way to compare the models in addition to predictive performance?  Whose model wins in that regard?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dc2a69-bf1e-4442-ad9e-22dc26e0f2b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "The model has a similar value to the ones run in the paper. The cross validation model by Elith et al. has an AUC value of 0.869 while we have an AUC of 0.874. Another way to compare the two models is by looking at the number of trees ran. We had a best number of trees value of 29 while they had 1050.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
