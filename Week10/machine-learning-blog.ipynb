{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Methods\n",
    "This notebook is a competition for my machine learning (EDS-232) class taught by Matteo Robbins. In this exercise, I will demonstrate machine learning methods to predict dissolved inorganic carbon (DIC) levels in water samples collected by the Califronia Cooperative Oceanic Fisheries Investigations program. This data was downloaded from the CalCOFI data portal, where bottle and cast data was merged, and releveant variables were selected. Data is split into a training and testing set. Machine learning models will be trained on the training set and then evaluated on the testing set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using multiple methods\n",
    "\n",
    "The goal of this exercise will be to demonstrate and optimize multiple machine learning methods. I am particularly interested in running a decision tree, random forest, and deep learning model for my data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train = pd.read_csv('data/train.csv')\n",
    "\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Lat_Dec</th>\n",
       "      <th>Lon_Dec</th>\n",
       "      <th>NO2uM</th>\n",
       "      <th>NO3uM</th>\n",
       "      <th>NH3uM</th>\n",
       "      <th>R_TEMP</th>\n",
       "      <th>R_Depth</th>\n",
       "      <th>R_Sal</th>\n",
       "      <th>R_DYNHT</th>\n",
       "      <th>R_Nuts</th>\n",
       "      <th>R_Oxy_micromol.Kg</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>PO4uM</th>\n",
       "      <th>SiO3uM</th>\n",
       "      <th>TA1.x</th>\n",
       "      <th>Salinity1</th>\n",
       "      <th>Temperature_degC</th>\n",
       "      <th>DIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34.385030</td>\n",
       "      <td>-120.665530</td>\n",
       "      <td>0.03</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.79</td>\n",
       "      <td>323</td>\n",
       "      <td>141.2</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.40948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.77</td>\n",
       "      <td>53.86</td>\n",
       "      <td>2287.45</td>\n",
       "      <td>34.198</td>\n",
       "      <td>7.82</td>\n",
       "      <td>2270.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>31.418333</td>\n",
       "      <td>-121.998333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.12</td>\n",
       "      <td>323</td>\n",
       "      <td>140.8</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.81441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.57</td>\n",
       "      <td>52.50</td>\n",
       "      <td>2279.10</td>\n",
       "      <td>34.074</td>\n",
       "      <td>7.15</td>\n",
       "      <td>2254.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>34.385030</td>\n",
       "      <td>-120.665530</td>\n",
       "      <td>0.18</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.68</td>\n",
       "      <td>50</td>\n",
       "      <td>246.8</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.29150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.29</td>\n",
       "      <td>13.01</td>\n",
       "      <td>2230.80</td>\n",
       "      <td>33.537</td>\n",
       "      <td>11.68</td>\n",
       "      <td>2111.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    Lat_Dec     Lon_Dec  NO2uM  NO3uM  NH3uM  R_TEMP  R_Depth  R_Sal  \\\n",
       "0   1  34.385030 -120.665530   0.03   33.8    0.0    7.79      323  141.2   \n",
       "1   2  31.418333 -121.998333   0.00   34.7    0.0    7.12      323  140.8   \n",
       "2   3  34.385030 -120.665530   0.18   14.2    0.0   11.68       50  246.8   \n",
       "\n",
       "   R_DYNHT  R_Nuts  R_Oxy_micromol.Kg  Unnamed: 12  PO4uM  SiO3uM    TA1.x  \\\n",
       "0    0.642     0.0           37.40948          NaN   2.77   53.86  2287.45   \n",
       "1    0.767     0.0           64.81441          NaN   2.57   52.50  2279.10   \n",
       "2    0.144     0.0          180.29150          NaN   1.29   13.01  2230.80   \n",
       "\n",
       "   Salinity1  Temperature_degC      DIC  \n",
       "0     34.198              7.82  2270.17  \n",
       "1     34.074              7.15  2254.10  \n",
       "2     33.537             11.68  2111.04  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View head of the dataset\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "Lat_Dec                 0\n",
       "Lon_Dec                 0\n",
       "NO2uM                   0\n",
       "NO3uM                   0\n",
       "NH3uM                   0\n",
       "R_TEMP                  0\n",
       "R_Depth                 0\n",
       "R_Sal                   0\n",
       "R_DYNHT                 0\n",
       "R_Nuts                  0\n",
       "R_Oxy_micromol.Kg       0\n",
       "Unnamed: 12          1454\n",
       "PO4uM                   0\n",
       "SiO3uM                  0\n",
       "TA1.x                   0\n",
       "Salinity1               0\n",
       "Temperature_degC        0\n",
       "DIC                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1454, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of the dataset\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 1454 rows in our training data. From our observations we also see that the column `Unnamed: 12` has missing values for every row. This data is useless so we can initially drop this column entirely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "Lat_Dec              0\n",
       "Lon_Dec              0\n",
       "NO2uM                0\n",
       "NO3uM                0\n",
       "NH3uM                0\n",
       "R_TEMP               0\n",
       "R_Depth              0\n",
       "R_Sal                0\n",
       "R_DYNHT              0\n",
       "R_Nuts               0\n",
       "R_Oxy_micromol.Kg    0\n",
       "PO4uM                0\n",
       "SiO3uM               0\n",
       "TA1.x                0\n",
       "Salinity1            0\n",
       "Temperature_degC     0\n",
       "DIC                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the column\n",
    "train = train.drop('Unnamed: 12', axis = 1)\n",
    "\n",
    "# Check if it dropped\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "Lat_Dec              float64\n",
       "Lon_Dec              float64\n",
       "NO2uM                float64\n",
       "NO3uM                float64\n",
       "NH3uM                float64\n",
       "R_TEMP               float64\n",
       "R_Depth                int64\n",
       "R_Sal                float64\n",
       "R_DYNHT              float64\n",
       "R_Nuts               float64\n",
       "R_Oxy_micromol.Kg    float64\n",
       "PO4uM                float64\n",
       "SiO3uM               float64\n",
       "TA1.x                float64\n",
       "Salinity1            float64\n",
       "Temperature_degC     float64\n",
       "DIC                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types of the columns\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our variables are composed of `float64`s and `int64`s meaning that they are numerical values. So, we can't use any classification models. The models I am initially interested in are a decision tree, random forest, and a deep learning model. Let's run through each one, one at a time, starting with a decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = train.drop(columns =['DIC'])\n",
    "y = train['DIC']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 808)\n",
    "\n",
    "# Scale data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_linear_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "linear_rmse = np.sqrt(mean_squared_error(y_test, y_linear_pred)) \n",
    "\n",
    "print(f\"Linear RMSE {linear_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge and Lasso Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.9111627561154896\n",
      "Ridge RMSE: 6.733\n"
     ]
    }
   ],
   "source": [
    "# Define a range of alphas (lambda)\n",
    "alphas = np.logspace(-4, 4, 100) # Alphas from 00001 to 10,000\n",
    "\n",
    "# Fit a RidgeCV with cross-validation\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv = 10).fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal alpha\n",
    "print(f\"Best Alpha: {ridge_cv.alpha_}\")\n",
    "\n",
    "# Make predictions\n",
    "y_ridge_pred = ridge_cv.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, y_ridge_pred))\n",
    "print(f\"Ridge RMSE: {ridge_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\.conda\\envs\\ml-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "10 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\thoma\\.conda\\envs\\ml-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\thoma\\.conda\\envs\\ml-env\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\thoma\\.conda\\envs\\ml-env\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\thoma\\.conda\\envs\\ml-env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\thoma\\.conda\\envs\\ml-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.93686982 0.99359599 0.9473278         nan 0.9354746  0.99469012\n",
      "        nan 0.9940775  0.80293767 0.80933766]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Define the parameters\n",
    "param_dist = {\n",
    "    'max_depth': [1, 2, 3, 4, 5, None],\n",
    "    'min_samples_split': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Tune the hyperparameters w/ GridSearchCV\n",
    "random_search = RandomizedSearchCV(dt, \n",
    "                           param_dist, \n",
    "                           cv = 5, ## 5-fold cross validation\n",
    "                           n_jobs = -1) ## Use all cores \n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_dt_params = random_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_dt_params}\")\n",
    "\n",
    "# Define best model variable for evaluation\n",
    "best_dt = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on our Training data 'test set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE: 8.834\n"
     ]
    }
   ],
   "source": [
    "# Predict on the best model\n",
    "y_dt_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Calculate RMSE from the best model\n",
    "dt_rmse = np.sqrt(mean_squared_error(y_test, y_dt_pred))\n",
    "print(f\"Decision Tree RMSE: {dt_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have calcualated the RMSE from our training data set in our model. Now, let's use the test set we intially loaded to evaluate how well our model will be on \"New\", \"Unknown\" data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare testing and training data \n",
    "# Make sure columns are the same as the training data\n",
    "\n",
    "# Create a conditional statement to check if the columns are the same\n",
    "\n",
    "test.columns.equals(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in test dataset but not in train dataset: {'TA1'}\n",
      "Columns in train dataset but not in test dataset: {'TA1.x', 'DIC'}\n"
     ]
    }
   ],
   "source": [
    "# Get the column names of both datasets\n",
    "train_columns = set(train.columns)\n",
    "test_columns = set(test.columns)\n",
    "\n",
    "# Find the differences in column names\n",
    "missing_in_train = test_columns - train_columns\n",
    "missing_in_test = train_columns - test_columns\n",
    "\n",
    "# Show the differences\n",
    "if missing_in_train or missing_in_test:\n",
    "    if missing_in_train:\n",
    "        print(f\"Columns in test dataset but not in train dataset: {missing_in_train}\")\n",
    "    if missing_in_test:\n",
    "        print(f\"Columns in train dataset but not in test dataset: {missing_in_test}\")\n",
    "else:\n",
    "    print(\"The datasets have the same column names.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see which columns are missing in each dataset. From the looks of it, it seems that the variable `TA1` and `TA1.x` are supposed to be the same, but are just spelled differently. We can fix that by renaming one to the other. It also look `DIC` is not in our testing set. This is expected as this is our target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Lat_Dec</th>\n",
       "      <th>Lon_Dec</th>\n",
       "      <th>NO2uM</th>\n",
       "      <th>NO3uM</th>\n",
       "      <th>NH3uM</th>\n",
       "      <th>R_TEMP</th>\n",
       "      <th>R_Depth</th>\n",
       "      <th>R_Sal</th>\n",
       "      <th>R_DYNHT</th>\n",
       "      <th>R_Nuts</th>\n",
       "      <th>R_Oxy_micromol.Kg</th>\n",
       "      <th>PO4uM</th>\n",
       "      <th>SiO3uM</th>\n",
       "      <th>TA1.x</th>\n",
       "      <th>Salinity1</th>\n",
       "      <th>Temperature_degC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1455</td>\n",
       "      <td>34.321666</td>\n",
       "      <td>-120.811666</td>\n",
       "      <td>0.02</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.51</td>\n",
       "      <td>101</td>\n",
       "      <td>189.9</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.41</td>\n",
       "      <td>138.838300</td>\n",
       "      <td>1.85</td>\n",
       "      <td>25.5</td>\n",
       "      <td>2244.94</td>\n",
       "      <td>33.830</td>\n",
       "      <td>9.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1456</td>\n",
       "      <td>34.275000</td>\n",
       "      <td>-120.033333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.84</td>\n",
       "      <td>102</td>\n",
       "      <td>185.2</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.00</td>\n",
       "      <td>102.709200</td>\n",
       "      <td>2.06</td>\n",
       "      <td>28.3</td>\n",
       "      <td>2253.27</td>\n",
       "      <td>33.963</td>\n",
       "      <td>9.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1457</td>\n",
       "      <td>34.275000</td>\n",
       "      <td>-120.033333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.60</td>\n",
       "      <td>514</td>\n",
       "      <td>124.1</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.174548</td>\n",
       "      <td>3.40</td>\n",
       "      <td>88.1</td>\n",
       "      <td>2316.95</td>\n",
       "      <td>34.241</td>\n",
       "      <td>6.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    Lat_Dec     Lon_Dec  NO2uM  NO3uM  NH3uM  R_TEMP  R_Depth  R_Sal  \\\n",
       "0  1455  34.321666 -120.811666   0.02   24.0   0.41    9.51      101  189.9   \n",
       "1  1456  34.275000 -120.033333   0.00   25.1   0.00    9.84      102  185.2   \n",
       "2  1457  34.275000 -120.033333   0.00   31.9   0.00    6.60      514  124.1   \n",
       "\n",
       "   R_DYNHT  R_Nuts  R_Oxy_micromol.Kg  PO4uM  SiO3uM    TA1.x  Salinity1  \\\n",
       "0    0.258    0.41         138.838300   1.85    25.5  2244.94     33.830   \n",
       "1    0.264    0.00         102.709200   2.06    28.3  2253.27     33.963   \n",
       "2    0.874    0.00           2.174548   3.40    88.1  2316.95     34.241   \n",
       "\n",
       "   Temperature_degC  \n",
       "0              9.52  \n",
       "1              9.85  \n",
       "2              6.65  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename TA1 to TA1.x to match our training data\n",
    "test = test.rename(columns = {'TA1': 'TA1.x'})\n",
    "\n",
    "# Check to see if the column was renamed\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make predictions on our test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\.conda\\envs\\ml-env\\lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_dt = best_dt.predict(test)\n",
    "\n",
    "# Create a dataframe containing ID and DIC for compeititon submission\n",
    "test['DIC'] = y_pred_dt\n",
    "submission = test[['id', 'DIC']]\n",
    "\n",
    "# Save the submission to a csv \n",
    "# submission.to_csv('submission_dt.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 7, 'max_features': 6, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Define hyperparameters\n",
    "param_grid = {\n",
    "    'max_features': ['sqrt', 6, None],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3,4,5,6,7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid = param_grid,\n",
    "    cv = 5, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the best hyperparameters\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Define the best model\n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 7.033\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m best_rf\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extract the feature importances\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mzip\u001b[39m(\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m, best_rf),\n\u001b[0;32m     13\u001b[0m                                    columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Sort the feature importances\u001b[39;00m\n\u001b[0;32m     16\u001b[0m importance_df \u001b[38;5;241m=\u001b[39m importance_df\u001b[38;5;241m.\u001b[39msort_values(by \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Predict on the best model\n",
    "y_rf_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Compute RMSE\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, y_rf_pred))\n",
    "print(f\"Mean Squared Error: {rf_rmse:.3f}\")\n",
    "\n",
    "# Extract features importances\n",
    "feature_importance = best_rf.feature_importances_\n",
    "\n",
    "# Extract the feature importances\n",
    "importance_df = pd.DataFrame(zip(X_test.columns, best_rf),\n",
    "                                   columns = ['Feature', 'Importance'])\n",
    "\n",
    "# Sort the feature importances\n",
    "importance_df = importance_df.sort_values(by = 'Importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize = (10, 6))\n",
    "sns.barplot(y = importance_df['Feature'], x = importance_df['Importance'])\n",
    "#sns.barplot(x = feature_importance, y = X.columns)\n",
    "plt.title('Feature Importance for determining nClimates')\n",
    "plt.ylabel('Feature')\n",
    "plt.xlabel('Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
